# Tech Report

### StockTwits (result.csv, result_sample.sql):
We collected this data from StockTwits, a social media platform designed for sharing stock sentiments and ideas between investors. Stocktwits has an API that retrieves posts with a Developer account. We retrieved data using the stocktwits RESTful API. This API doesn’t require a Python wrapper so we used curl commands like the following:  
curl -X GET https://api.stocktwits.com/api/2/streams/symbol/TSLA.json -o output.txt  
for now this api gives us access to many StockTwits features such as ticker, user streams, message, sentiment, timestamp...StockTwits is a reputable source given that many of the contributors are reputable investors. We are not trying to find accurate information about stock prices. We are trying to collect sentiment, and given StockTwits’ niche mission as a platform for retail traders we are confident that there will be correlation between sentiment and Stocktwits posts. We repeated api requests to create a sample since we can only retrieve 30 stocks at once which was an obstacle when preprocessing. In order to overcome this, we want to automate this process for the remainder of the project. We have 30 rows of sample data.These have attributes to distinguish between positive and negative sentiment. 30 rows represents a sample, and keeping collecting data based on the same attributes will be enough. The missing values we have are in the basic sentiment section, which gives a shortcut of understanding sentiment of a post without having to dive too deep in parsing text. However, for various reasons people can choose not to put a sentiment. This can create a challenge since we’ll have to predict sentiment from those posts, instead of knowing instantly. There are no duplicates since each post has a unique id. They are skewed since there are a lot more comments with the basic sentiment column “Bullish” which is an investing term for having a positive outlook on a stock.


### Russell and Tesla Stock Data (data.db, data.db sample):
The data for Russell3000 is collected from [Yahoo Finance](https://finance.yahoo.com/quote/%5ERUA/history/) (the raw data from the link can be found in Russell3000.csv) and the data for Tesla stock is collected from [NASDAQ](https://www.nasdaq.com/market-activity/stocks/tsla/historical) (the raw data from the link can be found in Tesla.csv). These sources are reputable and provided the most accessible information that met our data collection needs. 
The data sample was generated by using an [sqlite viewer](http://sqliteviewer.flowsoft7.com) and retrieving the first ten rows of each table. The sample is comparatively small but sufficiently represents the format of the complete dataset. It is not likely to exhibit sampling bias.  
The data is cleaned so that dates are formatted the same way for both stocks. Additionally, unnecessary symbols such as ‘$’ are removed from the data. A part of the data that is not as clean is many of the RussellVolume inputs are 0. 
There are 505 rows in the tesla_stock_data table, 479 rows in the russell_stock_data table, and 479 rows in the combined_stock_data table. Days where russell_stock_data was not available were omitted from the combined_stock_data table as the data is only valuable to us so that we can compare the relative prices of the funds, so data for both stocks needs to be available for the day to be a useful data point. This data represents two years (2019, 2020) worth of information which should be sufficient for the analysis stage. There is no duplicate data in the tables since each row represents a unique day in the time frame. 
There were no significant challenges in this stage of the data collection. We look forward to using this data as a comparison metric. Russell 3000 will be used to represent the general market, and will serve as a benchmark comparison value for drawing conclusions about Tesla stock performance.

# Twitter-scraped Data
Tweets were scraped using Selenium from the Twitter Search page. These are direct samplings of community-generated data about TSLA stock. I generated the sample using a python script running Selenium, which created a browser window to automate the scrolling and reading of the tweet results. It is comparatively small due to the significant amount of time required to scrape using Selenium. A source of bias we identified was the nature of the Twitter search function, in that the same tweets were served on identical searches. We worked around this by varying search parameters slightly (date, keywords, etc.). The data scraped was all from public Twitter accounts, i.e. users who are aware that their Tweets are visible to everyone. 
The data is cleaned so each column entry is of the correct type. The content of each tweet is further cleaned so as to not include any SQL-breaking characters like ‘\”’. The data could be further cleaned so as to exclude unrelated, profane, or potentially harmful tweets.
 Since the analysis part of the project trains a statistical model based on the tweet data, we can sample more tweets to augment the database if necessary by running the python script for tweets on other dates. This will particularly be the case if our model is underfitting. Since the tweets are selected at random, there is no meaningful distribution of the data. 
The biggest challenges presented in collecting this data is runtime. Selenium runs very slowly, and we want to collect as much data and as many tweets as possible, so we must continue to run the scraping script to augment the tweets database. Next steps include performing sentiment analysis on the body of each tweet, using VADER or similar. I noticed that many stock-related tweets that include images or other media content have little text, so we may have to decide whether or not to discard these tweets if they confuse the NLP program. 

