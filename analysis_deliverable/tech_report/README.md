# Tech Report

Our tech report is organized into the below three sections. In an attempt to create the most
effective hypothesis testing project, we took three different approaches to the hypothesis testing. This allowed us to experiment with different natural language processing API's, 
experiment with tuning parameters differently, and in some cases use different input data.  

Across these three sections that outline different approaches to testing the hypothesis, the hypothesis remains largely the same. The hypothesis is as follows:  

Null hypothesis- social media mentions of Tesla stock are not a good indicator of tesla stock price relative to the russell index fund.  
Alternative hypothesis - social media mentions of Tesla stock can be used as an indicator of stock price relative to the russell index fund.  

The first section outlines hypothesis testing relating to specifically Reddit mentions, whereas the following two sections focus on Twitter mentions.  

### Section 1 ###
This section corresponds to the files copy_of_copy_of_ds_reddit.py and stockprice.json.  
My hypothesis is that sentiment scores are correlated with stock prices changes from day to day. Therefore, I gather Reddit posts for each day, give every post a score and take the average for that day. I then compare the change of sentiment between two days with the stock price movement.  

We use regression and consider the r^2 value for the different datasets. We want to see if patterns in percentage change in stock are dependent or independent with respect to sentiment. I had to handle corrupted data especially for text. The datasets were also of different sizes and the days didn’t correspond to each other so we had to investigate unix timestamps and filter some days to make different datasets fit into each other in terms of size.  

We rejected the hypothesis that the price movement is dependent on Reddit sentiment. We knew that this was a long shot since the proprietary money is a lot larger in quantities, and sentiment doesn’t reflect anything about the bigger investors and the earnings dates(or any other event that is fundamental for stock price). We think that the sentiment on Reddit is also not predictive, but rather chasing since we do regression with actual price changes coming first.  

 No viz for Reddit yet.  
 
The main part where we acquire sentiment data is in our for loop that runs for 720 days, and makes a PushShift API call starting from January 1st 2019 to December 31st 2020. As we increment days one by one. After this call we plug the data into a dataframe, and analyze the body of the post. We use Sentiment Intensity Analyzer in order to get a sentiment score based on positive and negative keywords. A lot of Reddit users use terms that indicate strong sentiment that don’t exist in NLTK’s sentiment analysis library, therefore we started manually researching the website to see what these words mean and added them. Once we had daily sentiment change data, we got on Investing.com which gave us data about TSLA stock for our given dates. We were concerned about percentage change, therefore we parsed the strings in our stock price dataframe after reading the JSON. After turning these values into floats as well, we imported scipy to do Regression on the two datasets, and obtain the r_squared value.  

### Section 2 ###
This section corresponds to the files process_tweets.py and the .txt files in the tweets_processing_files folder.  
I used linear regression because this is a great test for determining the statistical relationship between two variables, namely the average sentiment of tesla mentions on twitter and tesla stock price performance relative to the russell index fund. The output of this test that I used to determine the validity of the hypothesis is the p-value and the r-squared value. If the p-value is less than 0.05 the null hypothesis is rejected and the alternative hypothesis is accepted. This test yielded a p-value of 0.008 which is significant and allows for the null hypothesis to be rejected and the alternative hypothesis accepted. The r-squared value is 0.04 which is not ideal. R-squared values are coefficients of determination. A high r-squared value can be an indication that the model is a good fit, however, this is not the only measure of goodness taken into account here. However, it is important to note that the r squared value is quite low so the linear regression line may not be a good fit for the data. This can also be seen on the scatterplot generated by the process_tweets.py file. However, the p-value still allows us to accept the hypothesis. 

A challenge for this portion of the project was having to do a lot of data restructuring because I needed to assign a sentiment score to each tweet, average the sentiment scores for each day, normalize the closing stock prices of tesla and the russell index fund, compute the relative stock price, and then line that data up with the average sentiment score 30 days prior.  

My interpretation of my results is that that the sentiment of tweets that mention twitter correlate to the closing stock price of twitter relative to the closing stock price of russell 30 days later. I think the results are probably accurate, however, it is important to note the smaller pool of data that the test was conducted on and the shortcomings of natural language processing in the API I used. Additionally, even though the p-value was promising, the r squared value is quite low and the scatterplot shows that a trend is not as readily apparent as one might hope when definitively evaluating the hypothesis. Some room for future improvement lies in using a larger time bracket, for example structure the data so that each column represents a week instead of a day. Using a larger timestep is more intuitive: we can expect that sentiment over the course of a week would be more likely to lead to a downstead change in stock performance, rather than seeing a change based on the sentiment of a specific day. This is a parameter that could be fine tuned in later iterations of the project.  

For the visualization, note that stock performance score is computed by subtracting the normalized tesla close price from the normalized russell close price, so the viewer can think of scores above 50 as instances where tesla is outperforming russell, and scores below 50 as instances where russell is outperforming tesla - where individual stock/fund close price is normalized so that it is relative to the stock/fund's minimum and maximum close prices over the course of the year.   

[visualization is available here](../visualizations/twitter_linear_regression.png)
I picked this graph because the scatterplot allows a great visual representation of the output of the linear regression model. The indendent variable is displayed on the x axis and the dependent variable on the y axis, and the line of best fit is overlayed on the data points. I don't think there is another great way to demonstrate so clearly the independent and dependent variables alongside the linear regression line. However, one challenge in visualizing the results is that it is not apparent how the independent and dependent variables evolve over time. Although I think my visualization does portray key points to the viewer on its own, Reading this report in addition to viewing the graph is helpful so that the viewer can understand how the metrics are calculated and what conclusions can be drawn from the graphs. This will encourage viewers to make reasonable conclusions, so that our results are not misinterpreted. 

The process for how I perform the analysis is outlined below. First, I connect to the database that stores the tweets and select the text for each tweet using an sql statement. I also select the dates for each of these tweets. I then compute an average sentiment score for each day, by averaging the sentiment scores for all the tweets published on that day. The sentiment scores are found by interacting with an NLP API found online using the curl script in tweets_processing_files/curl_script.txt. The API assigns a 0 to negative sentiment tweets, a 2 to neutral tweets, and a 4 to positive tweets. The results of this can be seen in the api_output.txt file. Then, in order to make the russell close price data able to be meaningfully compared to the tesla close price data, I normalize the values on a scale of 0-1 that represents how the close price relates to the minimum and maximum close prices for each fund in the database. I then create a table of the average sentiment score of tweets, and then the relative stock price 30 days later for each day. The relative stock price is computed by subtracting the tesla normalized close price from the russell normalized close price. I then perform linear regression on this using average sentiment of Tesla mentions on Twitter as the independent variable, and relative stock performance exactly 30 days later as the dependent variable. I use the scipy stats library for the linear regression and print out the results.  

I think there are confounding trends or variables present in the data that I perform the statistical test on, as there usually is when dealing with social media data. The same websites, news articles, and news television that affects investor behavior on the stock market will affect twitter users’ behavior when they publish tweets on the internet. It is hard to think of a way to control for these confounding variables because the affect of other media on twitter is so pervasive.  

The future direction to go in for these results is seeing if performing the test on more data will change the results. It also could be useful to bracket the data into time periods, so we could see if the average sentiment of tesla twitter mentions over the course of a week rather than a day correlates to the relative stock price. 

[Code for this portion here](../process_tweets.py)
[Files generated by the code here - useful for seeing step by step process](../tweets_processing_files)

## Section 3 - Using VADER analysis to perform multiple regression on Tweet data

[Python Scripts here](../tweet_vader_regression)

### Hypothesis ###

The null hypothesis in this task was that the sentiment of Tweets related to TSLA stock is not a good indicator of the current price of TSLA stock. The alternative hypothesis is that the sentiment of Tweets related to TSLA stock is a good indicator of the current price of TSLA stock. I use a multiple regression model trained on one year of Tweet data and publicly available stock data to evaluate the statistical significance of the relationship between the two. A p-value below 0.05 would demonstrate a significant relationship. 

### Process ###
I use multiple regression because it allows me to introduce a number of salient data points in evaluating the relationship between TSLA tweets and stock price. I used the VADER sentiment analysis algorithm to determine the polarity of each TSLA-related tweet I had scraped, assigning each tweet a positive, negative, and neutral score. Each tweet also had a certain number of likes and comments. I averaged each VADER score for a given day of tweets and summed the number of likes and comments on all tweets in a given day to create [sentiments.csv](../tweet_vader_regression/sentiments.csv), a table of the aggregated positive, negative, and neutral sentiment values as well as likes and comments for a sample of tweets for each day in 2020. 

I then ran a multiple regression test using the values in sentiments.csv, where the dependent variable was the percent change in stock price on a given day. I measured success using the resultant p-value. I do not think r^2 is a good metric by which to judge the model because tweets are human-generated and sentiment data is inherently noisy, almost guaranteeing a low R^2-value. 

I had to significantly restructure my data, as described above, reformatting tesla_tweets.db, which simply held raw tweets, into usable sentiment data for given days. This involved analyzing tweets individually and then aggregating them by date so they could be compared to the day’s stock price, as described above. 

### Results ###
The multiple regression test resulted in a p-value of 0.0627. This means that, given the sample of data, there is a 6% chance the null hypothesis is true. While evidence that the proposed relationship is not a coincidence, it is not enough to reject the null hypothesis. This would require a p-value less than 0.05. 
I am fairly confident in our results, given that we used a year of Twitter data and several data points. I think there is evidence of a relationship, and that with less noisy and more accurate data it can be concretely demonstrated. 

### Visualization ###
I picked [this graph](../visualizations/tesla_tweets_viz1.png)because it represents the relationship between the independent variable of highest coefficient in my multiple regression model with the dependent variable. This independent variable is the aggregated negative sentiment value of tweets on a given day, and there is a slight correlation between it and the change in stock price for that day, as demonstrated in the visualization. There were several challenges in visualizing the results, chief among which was visualizing the relationship of the dependent variable with multiple independent variables. This could have been done with a 3-dimensional scatter plot, but was messy and unclear. Ultimately, I opted to clearly show the relationship with the most significant independent variable. 
